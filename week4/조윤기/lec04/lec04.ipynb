{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 04-1. multi-variable linear regression을 Tensorflow 에서 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis without matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step\n",
      "  Cost: 62215.58203125\n",
      "  Prediction: [-71.54681  -80.762856 -82.81272  -84.13084  -65.19802 ]\n",
      "\n",
      "100 step\n",
      "  Cost: 10.333416938781738\n",
      "  Prediction: [149.73466 185.24025 179.26546 201.2524  137.71626]\n",
      "\n",
      "200 step\n",
      "  Cost: 10.262008666992188\n",
      "  Prediction: [149.71536 185.25491 179.26141 201.23463 137.74811]\n",
      "\n",
      "300 step\n",
      "  Cost: 10.1920747756958\n",
      "  Prediction: [149.69676 185.2692  179.25764 201.21707 137.77933]\n",
      "\n",
      "400 step\n",
      "  Cost: 10.123557090759277\n",
      "  Prediction: [149.67883 185.28304 179.25407 201.1997  137.80995]\n",
      "\n",
      "500 step\n",
      "  Cost: 10.056477546691895\n",
      "  Prediction: [149.6615  185.29636 179.25066 201.18246 137.83989]\n",
      "\n",
      "600 step\n",
      "  Cost: 9.990674018859863\n",
      "  Prediction: [149.64484 185.30925 179.24742 201.16542 137.86926]\n",
      "\n",
      "700 step\n",
      "  Cost: 9.926172256469727\n",
      "  Prediction: [149.62878 185.32176 179.2444  201.14856 137.89804]\n",
      "\n",
      "800 step\n",
      "  Cost: 9.862924575805664\n",
      "  Prediction: [149.61331 185.33386 179.24156 201.1319  137.92627]\n",
      "\n",
      "900 step\n",
      "  Cost: 9.800724983215332\n",
      "  Prediction: [149.5984  185.34557 179.23886 201.11533 137.95393]\n",
      "\n",
      "1000 step\n",
      "  Cost: 9.739729881286621\n",
      "  Prediction: [149.58405 185.35686 179.23634 201.09895 137.98105]\n",
      "\n",
      "1100 step\n",
      "  Cost: 9.679666519165039\n",
      "  Prediction: [149.57025 185.36777 179.23398 201.08269 138.00764]\n",
      "\n",
      "1200 step\n",
      "  Cost: 9.620626449584961\n",
      "  Prediction: [149.55702 185.37833 179.2318  201.0666  138.03374]\n",
      "\n",
      "1300 step\n",
      "  Cost: 9.562582015991211\n",
      "  Prediction: [149.54427 185.38852 179.22977 201.05066 138.05933]\n",
      "\n",
      "1400 step\n",
      "  Cost: 9.505473136901855\n",
      "  Prediction: [149.53203 185.39836 179.22786 201.03487 138.08443]\n",
      "\n",
      "1500 step\n",
      "  Cost: 9.449197769165039\n",
      "  Prediction: [149.5203  185.40788 179.22614 201.01921 138.10907]\n",
      "\n",
      "1600 step\n",
      "  Cost: 9.393820762634277\n",
      "  Prediction: [149.509   185.41707 179.22453 201.00368 138.13322]\n",
      "\n",
      "1700 step\n",
      "  Cost: 9.339287757873535\n",
      "  Prediction: [149.49818 185.42595 179.22305 200.98831 138.15695]\n",
      "\n",
      "1800 step\n",
      "  Cost: 9.285487174987793\n",
      "  Prediction: [149.48782 185.43452 179.22173 200.97307 138.18025]\n",
      "\n",
      "1900 step\n",
      "  Cost: 9.232545852661133\n",
      "  Prediction: [149.47786 185.44276 179.2205  200.95796 138.2031 ]\n",
      "\n",
      "2000 step\n",
      "  Cost: 9.180310249328613\n",
      "  Prediction: [149.46835 185.45074 179.21942 200.943   138.22552]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(f'{step} step\\n  Cost: {cost_val}\\n  Prediction: {hy_val}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 y 값: [152, 185, 180, 196, 142]  \n",
    "  \n",
    "Matrix 없으면 코드가 더러워진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis with matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step\n",
      "  Cost: 111693.7734375\n",
      "  Prediction:\n",
      "[[-137.52034]\n",
      " [-176.87514]\n",
      " [-168.22125]\n",
      " [-184.51347]\n",
      " [-136.64798]]\n",
      "\n",
      "100 step\n",
      "  Cost: 26.079437255859375\n",
      "  Prediction:\n",
      "[[158.78397]\n",
      " [179.63939]\n",
      " [182.86156]\n",
      " [197.82892]\n",
      " [135.35881]]\n",
      "\n",
      "200 step\n",
      "  Cost: 24.712373733520508\n",
      "  Prediction:\n",
      "[[158.58862]\n",
      " [179.77333]\n",
      " [182.80174]\n",
      " [197.78525]\n",
      " [135.53494]]\n",
      "\n",
      "300 step\n",
      "  Cost: 23.4173583984375\n",
      "  Prediction:\n",
      "[[158.3985 ]\n",
      " [179.9037 ]\n",
      " [182.74355]\n",
      " [197.74275]\n",
      " [135.70639]]\n",
      "\n",
      "400 step\n",
      "  Cost: 22.190670013427734\n",
      "  Prediction:\n",
      "[[158.21347]\n",
      " [180.0306 ]\n",
      " [182.6869 ]\n",
      " [197.70134]\n",
      " [135.87325]]\n",
      "\n",
      "500 step\n",
      "  Cost: 21.028743743896484\n",
      "  Prediction:\n",
      "[[158.0334 ]\n",
      " [180.15408]\n",
      " [182.63179]\n",
      " [197.66109]\n",
      " [136.03566]]\n",
      "\n",
      "600 step\n",
      "  Cost: 19.928081512451172\n",
      "  Prediction:\n",
      "[[157.85814]\n",
      " [180.27426]\n",
      " [182.57811]\n",
      " [197.62184]\n",
      " [136.19371]]\n",
      "\n",
      "700 step\n",
      "  Cost: 18.885540008544922\n",
      "  Prediction:\n",
      "[[157.6876 ]\n",
      " [180.39125]\n",
      " [182.52594]\n",
      " [197.58368]\n",
      " [136.34758]]\n",
      "\n",
      "800 step\n",
      "  Cost: 17.897945404052734\n",
      "  Prediction:\n",
      "[[157.52159]\n",
      " [180.50508]\n",
      " [182.47511]\n",
      " [197.54652]\n",
      " [136.49731]]\n",
      "\n",
      "900 step\n",
      "  Cost: 16.96249008178711\n",
      "  Prediction:\n",
      "[[157.36002]\n",
      " [180.61584]\n",
      " [182.42564]\n",
      " [197.51031]\n",
      " [136.64304]]\n",
      "\n",
      "1000 step\n",
      "  Cost: 16.076358795166016\n",
      "  Prediction:\n",
      "[[157.20279]\n",
      " [180.7237 ]\n",
      " [182.3775 ]\n",
      " [197.47513]\n",
      " [136.78488]]\n",
      "\n",
      "1100 step\n",
      "  Cost: 15.236953735351562\n",
      "  Prediction:\n",
      "[[157.04976]\n",
      " [180.82864]\n",
      " [182.33066]\n",
      " [197.44084]\n",
      " [136.92294]]\n",
      "\n",
      "1200 step\n",
      "  Cost: 14.441858291625977\n",
      "  Prediction:\n",
      "[[156.90083]\n",
      " [180.93079]\n",
      " [182.28508]\n",
      " [197.40749]\n",
      " [137.05733]]\n",
      "\n",
      "1300 step\n",
      "  Cost: 13.688699722290039\n",
      "  Prediction:\n",
      "[[156.75587]\n",
      " [181.03018]\n",
      " [182.24072]\n",
      " [197.37498]\n",
      " [137.18811]]\n",
      "\n",
      "1400 step\n",
      "  Cost: 12.975285530090332\n",
      "  Prediction:\n",
      "[[156.61482]\n",
      " [181.12694]\n",
      " [182.19756]\n",
      " [197.34337]\n",
      " [137.31541]]\n",
      "\n",
      "1500 step\n",
      "  Cost: 12.299479484558105\n",
      "  Prediction:\n",
      "[[156.47754]\n",
      " [181.2211 ]\n",
      " [182.15552]\n",
      " [197.31258]\n",
      " [137.43932]]\n",
      "\n",
      "1600 step\n",
      "  Cost: 11.659337043762207\n",
      "  Prediction:\n",
      "[[156.34393]\n",
      " [181.31276]\n",
      " [182.11465]\n",
      " [197.28262]\n",
      " [137.55992]]\n",
      "\n",
      "1700 step\n",
      "  Cost: 11.052983283996582\n",
      "  Prediction:\n",
      "[[156.21388]\n",
      " [181.40193]\n",
      " [182.07484]\n",
      " [197.25343]\n",
      " [137.67728]]\n",
      "\n",
      "1800 step\n",
      "  Cost: 10.478628158569336\n",
      "  Prediction:\n",
      "[[156.08731]\n",
      " [181.48871]\n",
      " [182.0361 ]\n",
      " [197.22504]\n",
      " [137.7915 ]]\n",
      "\n",
      "1900 step\n",
      "  Cost: 9.934526443481445\n",
      "  Prediction:\n",
      "[[155.96414]\n",
      " [181.5732 ]\n",
      " [181.99841]\n",
      " [197.19736]\n",
      " [137.9027 ]]\n",
      "\n",
      "2000 step\n",
      "  Cost: 9.41916275024414\n",
      "  Prediction:\n",
      "[[155.84427]\n",
      " [181.65541]\n",
      " [181.96172]\n",
      " [197.17046]\n",
      " [138.01091]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "# placeholder for a tensor that will be always fed\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = \\\n",
    "        sess.run([cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(f'{step} step\\n  Cost: {cost_val}\\n  Prediction:\\n{hy_val}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 04-2. TensorFlow로 파일에서 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]] 6\n",
      "(6, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step\n",
      "  Cost: 20344.2734375\n",
      "  Prediction:\n",
      "[[22.048063 ]\n",
      " [21.619787 ]\n",
      " [24.096693 ]\n",
      " [22.293005 ]\n",
      " [18.633902 ]\n",
      " [ 7.2669735]]\n",
      "\n",
      "100 step\n",
      "  Cost: 6.353769302368164\n",
      "  Prediction:\n",
      "[[155.79639]\n",
      " [182.60619]\n",
      " [182.59769]\n",
      " [194.92845]\n",
      " [141.45721]\n",
      " [ 97.87128]]\n",
      "\n",
      "200 step\n",
      "  Cost: 6.034921169281006\n",
      "  Prediction:\n",
      "[[155.69016 ]\n",
      " [182.65692 ]\n",
      " [182.55382 ]\n",
      " [194.90393 ]\n",
      " [141.5211  ]\n",
      " [ 97.975174]]\n",
      "\n",
      "300 step\n",
      "  Cost: 5.7362751960754395\n",
      "  Prediction:\n",
      "[[155.5874 ]\n",
      " [182.70596]\n",
      " [182.51134]\n",
      " [194.88031]\n",
      " [141.58273]\n",
      " [ 98.0758 ]]\n",
      "\n",
      "400 step\n",
      "  Cost: 5.456491947174072\n",
      "  Prediction:\n",
      "[[155.48799 ]\n",
      " [182.75337 ]\n",
      " [182.47021 ]\n",
      " [194.8576  ]\n",
      " [141.6422  ]\n",
      " [ 98.173256]]\n",
      "\n",
      "500 step\n",
      "  Cost: 5.194362163543701\n",
      "  Prediction:\n",
      "[[155.39178]\n",
      " [182.79918]\n",
      " [182.4304 ]\n",
      " [194.83575]\n",
      " [141.69955]\n",
      " [ 98.26765]]\n",
      "\n",
      "600 step\n",
      "  Cost: 4.948755264282227\n",
      "  Prediction:\n",
      "[[155.29875]\n",
      " [182.84352]\n",
      " [182.39188]\n",
      " [194.81474]\n",
      " [141.75491]\n",
      " [ 98.35909]]\n",
      "\n",
      "700 step\n",
      "  Cost: 4.718599796295166\n",
      "  Prediction:\n",
      "[[155.2087 ]\n",
      " [182.88632]\n",
      " [182.35454]\n",
      " [194.79451]\n",
      " [141.80827]\n",
      " [ 98.44766]]\n",
      "\n",
      "800 step\n",
      "  Cost: 4.502951622009277\n",
      "  Prediction:\n",
      "[[155.12161 ]\n",
      " [182.92772 ]\n",
      " [182.3184  ]\n",
      " [194.7751  ]\n",
      " [141.85974 ]\n",
      " [ 98.533455]]\n",
      "\n",
      "900 step\n",
      "  Cost: 4.3008246421813965\n",
      "  Prediction:\n",
      "[[155.03734]\n",
      " [182.96773]\n",
      " [182.2834 ]\n",
      " [194.7564 ]\n",
      " [141.9094 ]\n",
      " [ 98.61658]]\n",
      "\n",
      "1000 step\n",
      "  Cost: 4.111353397369385\n",
      "  Prediction:\n",
      "[[154.95578]\n",
      " [183.00641]\n",
      " [182.2495 ]\n",
      " [194.73842]\n",
      " [141.95724]\n",
      " [ 98.69708]]\n",
      "\n",
      "1100 step\n",
      "  Cost: 3.933756113052368\n",
      "  Prediction:\n",
      "[[154.8769  ]\n",
      " [183.04381 ]\n",
      " [182.2167  ]\n",
      " [194.72119 ]\n",
      " [142.00339 ]\n",
      " [ 98.775116]]\n",
      "\n",
      "1200 step\n",
      "  Cost: 3.767298460006714\n",
      "  Prediction:\n",
      "[[154.80058 ]\n",
      " [183.07993 ]\n",
      " [182.18494 ]\n",
      " [194.7046  ]\n",
      " [142.04787 ]\n",
      " [ 98.850685]]\n",
      "\n",
      "1300 step\n",
      "  Cost: 3.611180543899536\n",
      "  Prediction:\n",
      "[[154.72675]\n",
      " [183.11487]\n",
      " [182.15414]\n",
      " [194.68869]\n",
      " [142.09076]\n",
      " [ 98.92392]]\n",
      "\n",
      "1400 step\n",
      "  Cost: 3.464812994003296\n",
      "  Prediction:\n",
      "[[154.65529]\n",
      " [183.14864]\n",
      " [182.12436]\n",
      " [194.67342]\n",
      " [142.1321 ]\n",
      " [ 98.99486]]\n",
      "\n",
      "1500 step\n",
      "  Cost: 3.327547073364258\n",
      "  Prediction:\n",
      "[[154.58617]\n",
      " [183.18124]\n",
      " [182.09547]\n",
      " [194.65872]\n",
      " [142.1719 ]\n",
      " [ 99.06362]]\n",
      "\n",
      "1600 step\n",
      "  Cost: 3.1988258361816406\n",
      "  Prediction:\n",
      "[[154.5193  ]\n",
      " [183.21278 ]\n",
      " [182.06757 ]\n",
      " [194.64465 ]\n",
      " [142.2103  ]\n",
      " [ 99.130264]]\n",
      "\n",
      "1700 step\n",
      "  Cost: 3.078068971633911\n",
      "  Prediction:\n",
      "[[154.45459]\n",
      " [183.24323]\n",
      " [182.04047]\n",
      " [194.63113]\n",
      " [142.24725]\n",
      " [ 99.19481]]\n",
      "\n",
      "1800 step\n",
      "  Cost: 2.964735269546509\n",
      "  Prediction:\n",
      "[[154.39198]\n",
      " [183.27269]\n",
      " [182.01424]\n",
      " [194.6182 ]\n",
      " [142.28287]\n",
      " [ 99.25739]]\n",
      "\n",
      "1900 step\n",
      "  Cost: 2.8584067821502686\n",
      "  Prediction:\n",
      "[[154.33138]\n",
      " [183.30116]\n",
      " [181.98886]\n",
      " [194.60576]\n",
      " [142.31715]\n",
      " [ 99.31803]]\n",
      "\n",
      "2000 step\n",
      "  Cost: 2.758619546890259\n",
      "  Prediction:\n",
      "[[154.27278 ]\n",
      " [183.32866 ]\n",
      " [181.96426 ]\n",
      " [194.5939  ]\n",
      " [142.35019 ]\n",
      " [ 99.376816]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                   feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(f'{step} step\\n  Cost: {cost_val}\\n  Prediction:\\n{hy_val}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be\n",
      "  [[171.15341]]\n",
      "Other score will be\n",
      "  [[106.725494]\n",
      " [197.8313  ]]\n"
     ]
    }
   ],
   "source": [
    "# Ask my score\n",
    "print(f\"Your score will be\\n  {sess.run(hypothesis, feed_dict={X:[[100, 70, 101]]})}\")\n",
    "                \n",
    "print(f\"Other score will be\\n  {sess.run(hypothesis, feed_dict={X:[[60, 70, 110], [90, 100, 80]]})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Runners\n",
    "\n",
    "file이 아주 클 때 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](lec04.assets/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queue runner 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (3,) for Tensor 'Placeholder_31:0', which has shape '(?, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9617419afcdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     _cost, _hy, _ = sess.run(\n\u001b[1;32m     46\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     feed_dict={X:x_batch, Y:y_batch})\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{step} step\\n  Cost: {_cost}\\n  Prediction:\\n{_hy}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (3,) for Tensor 'Placeholder_31:0', which has shape '(?, 1)'"
     ]
    }
   ],
   "source": [
    "# make filename queue\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data-01-test-score.csv', 'data-02-test-score.csv'],\n",
    "    shuffle=False, name='filename_queue')\n",
    "\n",
    "# reader & read filename queue\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# parse value (decode)\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]  # data type 및 default 값 정의\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[:-1], xy[-1]], batch_size=3)  # batch_size: 10개씩 가져온다\n",
    "    \n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    _cost, _hy, _ = sess.run(\n",
    "                    [cost, hypothesis, train],\n",
    "                    feed_dict={X:x_batch, Y:y_batch})\n",
    "    if step % 100 == 0:\n",
    "        print(f'{step} step\\n  Cost: {_cost}\\n  Prediction:\\n{_hy}\\n')\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
